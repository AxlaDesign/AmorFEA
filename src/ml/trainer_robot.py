'''Train the neural network to be a powerful PDE solver, where physical laws have been built in
Linear case
'''

import torch
from torch import optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import numpy as np
import os
import collections
from .trainer import Trainer, batch_mat_vec, normalize_adj, boundary_flag_matrix
from .models import LinearRegressor, MLP, GCN, MixedNetwork, RobotNetwork
from ..pde.soft_robot import SoftRobot
from .. import arguments
from ..graph.visualization import *


class TrainerRobot(Trainer):
    def __init__(self, args):
        super(TrainerRobot, self).__init__(args)
        self.poisson = SoftRobot(self.args)


    def loss_function(self, x_control, x_state):
        young_mod = 100
        poisson_ratio = 0.3
        shear_mod = young_mod / (2 * (1 + poisson_ratio))
        bulk_mod = young_mod / (3 * (1 - 2*poisson_ratio))

        F00 = batch_mat_vec(self.F00, x_state) + 1
        F01 = batch_mat_vec(self.F01, x_state)
        F10 = batch_mat_vec(self.F10, x_state)
        F11 = batch_mat_vec(self.F11, x_state) + 1

        J = F00*F11 - F01*F10
        Jinv = J**(-2 / 3)
        I1 = F00*F00 + F01*F01 + F10*F10 + F11*F11

        energy_density = ((shear_mod / 2) * (Jinv * (I1 + 1) - 3) +
                          (bulk_mod / 2) * (J - 1)**2)  

        loss = (energy_density * self.weight_area).sum()

        return loss
 

    def initialization(self):

        bc_btm, bc_lx, bc_ly, bc_rx, bc_ry = self.poisson.boundary_flags_list
 
        bc_btm_mat = boundary_flag_matrix(bc_btm)
        bc_lx_mat = boundary_flag_matrix(bc_lx)
        bc_ly_mat = boundary_flag_matrix(bc_ly)
        bc_rx_mat = boundary_flag_matrix(bc_rx)
        bc_ry_mat = boundary_flag_matrix(bc_ry)

        lx_0, ly_0, rx_0, ry_0 = 0, 0, 1, 0
        lx = np.matmul(bc_lx_mat, self.poisson.coo_dof[:, 0])
        lx_new = np.diff(np.insert(lx, 0, lx_0))
        ly = np.matmul(bc_lx_mat, self.poisson.coo_dof[:, 1])
        ly_new = np.diff(np.insert(ly, 0, ly_0))
        rx = np.matmul(bc_rx_mat, self.poisson.coo_dof[:, 0])
        rx_new = np.diff(np.insert(rx, 0, rx_0))
        ry = np.matmul(bc_rx_mat, self.poisson.coo_dof[:, 1])
        ry_new = np.diff(np.insert(ry, 0, ry_0))
        lr = np.sqrt(lx_new**2 + ly_new**2)
        rr = np.sqrt(rx_new**2 + ry_new**2)
        joints = [torch.tensor(lr).float(), torch.tensor(rr).float()]
        coo_diff = [torch.tensor(lx_0 - lx).float(), torch.tensor(ly_0 - ly).float(),
                    torch.tensor(rx_0 - rx).float(), torch.tensor(ry_0 - ry).float()]


        # Subject to change. Raw data generated by some distribution
        raw_data = np.load(self.args.root_path + '/' + self.args.numpy_path + '/robot/' + self.poisson.name 
                              +'-Gaussian-3000-' + str(self.poisson.num_dofs) + '.npy')

        left_data = np.transpose(np.matmul(bc_lx_mat, raw_data.transpose())) 
        right_data = np.transpose(np.matmul(bc_rx_mat, raw_data.transpose()))

        # Debug
        left_data = 0.1*np.ones_like(left_data)
        right_data = -0.1*np.ones_like(right_data)


        self.data_X = np.concatenate((left_data, right_data), axis=1)
        self.args.input_size = self.data_X.shape[1]
        self.train_loader, self.test_loader = self.shuffle_data()

        F00, F01, F10, F11 = self.poisson.compute_operators()
        self.F00 = torch.tensor(F00).float().to_sparse()
        self.F01 = torch.tensor(F01).float().to_sparse()
        self.F10 = torch.tensor(F10).float().to_sparse()
        self.F11 = torch.tensor(F11).float().to_sparse()
        self.weight_area = torch.tensor(self.poisson.compute_areas()).float()

        bc_btm_mat = torch.tensor(bc_btm_mat).float().to_sparse()
        bc_lx_mat = torch.tensor(bc_lx_mat).float().to_sparse()
        bc_ly_mat = torch.tensor(bc_ly_mat).float().to_sparse()
        bc_rx_mat = torch.tensor(bc_rx_mat).float().to_sparse()
        bc_ry_mat = torch.tensor(bc_ry_mat).float().to_sparse()
        bc_mat_list = [bc_btm_mat, bc_lx_mat, bc_ly_mat, bc_rx_mat, bc_ry_mat]

        bc_btm = torch.tensor(bc_btm).float()
        bc_lx = torch.tensor(bc_lx).float()
        bc_ly = torch.tensor(bc_ly).float()
        bc_rx = torch.tensor(bc_rx).float()
        bc_ry = torch.tensor(bc_ry).float() 
        bc_list = [bc_btm, bc_lx, bc_ly, bc_rx, bc_ry]
  
        self.graph_info = [bc_mat_list, bc_list, joints, coo_diff]

 
    def run(self):
        self.initialization()

        self.model = RobotNetwork(self.args, self.graph_info)
        # self.model.fc.weight.data = torch.zeros((self.args.input_size, self.args.input_size))

        self.optimizer = optim.Adam(self.model.parameters(), lr=5*1e-4)
        # self.optimizer = optim.LBFGS(self.model.parameters(), lr=1e-2, max_iter=20, history_size=40)
        # self.optimal tuning lr=1e-1, momentum=0.6 for multinomial data
        # self.optimal tuning lr=1e-4, momentum=0.85 for uniform data
        # self.optimizer = optim.SGD(self.model.parameters(), lr=1e-6, momentum=0.85)

        for epoch in range(self.args.epochs):
            train_loss = self.train(epoch)
            # test_loss = self.test_by_loss(epoch)
            # mean_L2_error = self.test_by_FEM(epoch)

            self.fem_test = self.test_X[:1]
            recon_batch = self.model(self.fem_test)
            scalar_field_paraview(self.args, recon_batch[0].data.numpy(), self.poisson, "nn")

            print('\n\n')

            # if True:
            #     torch.save(self.model, self.args.root_path + '/' + self.args.model_path + '/linear/model_' + str(0))

    def debug(self):
        source = torch.ones(self.poisson.num_dofs).unsqueeze(0)
        solution = self.model(source)
        scalar_field_paraview(self.args, solution.data.numpy().flatten(), self.poisson, "ok")


if __name__ == "__main__":
    args = arguments.args
    trainer = TrainerRobot(args)
    trainer.run()