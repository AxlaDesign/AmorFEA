'''Train the neural network to be a powerful PDE solver, where physical laws have been built in
Linear case
'''

import torch
from torch import optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import numpy as np
import os
import collections
from .trainer import Trainer, batch_mat_vec, normalize_adj
from .models import LinearRegressor, MLP, GCN, MixedNetwork
from ..pde.poisson_trapezoid import PoissonTrapezoid
from .. import arguments
from ..graph.visualization import *


class TrainerNonlinear(Trainer):
    def __init__(self, args):
        super(TrainerNonlinear, self).__init__(args)
        self.poisson = PoissonTrapezoid(self.args)
        self.args.input_size = self.poisson.num_dofs

    def loss_function(self, x_control, x_state):
        # loss function is defined so that PDE is satisfied

        # x_control should be torch tensor with shape (batch, input_size)
        # x_state should be torch tensor with shape (batch, input_size)
        assert(x_control.shape == x_state.shape and len(x_control.shape) == 2)
     
        term1 = batch_mat_vec(self.A_sp, x_state)
        term1 = 0.5*term1*x_state
        
        term2 = 0.5*x_state**2*self.weight_area
        term3 = 0.25*x_state**4*self.weight_area
        
        term4 = batch_mat_vec(self.B_sp, x_control)
        term4 = term4*x_state

        loss = term1.sum() + term2.sum() + term3.sum() - term4.sum()
        return loss

    def initialization(self):

        # Subject to change. Raw data generated by some distribution
        self.data_X = np.load(self.args.root_path + '/' + self.args.numpy_path + '/nonlinear/' + self.poisson.name 
                              +'-Gaussian-30000-' + str(self.poisson.num_dofs) + '.npy')
        self.train_loader, self.test_loader = self.shuffle_data()

        A_np, B_np = self.poisson.compute_operators()
        A = torch.tensor(A_np).float()
        B = torch.tensor(B_np).float()
        self.A_sp = A.to_sparse()
        self.B_sp = B.to_sparse()

        self.weight_area = torch.tensor(self.poisson.get_weight_area()).float()

        # Can be much more general
        # Fixed bc for now
        bc_flag_1 = torch.tensor(self.poisson.boundary_flags_list[0]).float()
        bc_value_1 = 0.*bc_flag_1
        bc_flag_2 = torch.tensor(self.poisson.boundary_flags_list[1]).float()
        bc_value_2 = 0.*bc_flag_2
        bc_value = bc_value_1 + bc_value_2
        interior_flag = torch.ones(self.poisson.num_vertices) - bc_flag_1 - bc_flag_2
        adjacency_matrix = self.poisson.get_adjacency_matrix()
        A_normalized = normalize_adj(adjacency_matrix)
        self.graph_info = [bc_value, interior_flag, A_normalized, self.B_sp]
        self.reset_matrix_boundary = np.diag(self.poisson.boundary_flags)
        self.reset_matrix_interior = np.identity(self.poisson.num_dofs) - self.reset_matrix_boundary

        self.FEM_evaluation()  

    def run(self):
        self.initialization()

        self.model = MixedNetwork(self.args, self.graph_info)
        # self.model.fc.weight.data = torch.zeros((self.args.input_size, self.args.input_size))

        self.optimizer = optim.Adam(self.model.parameters(), lr=5*1e-4)
        # self.optimizer = optim.LBFGS(self.model.parameters(), lr=1e-2, max_iter=20, history_size=40)
        # self.optimal tuning lr=1e-1, momentum=0.6 for multinomial data
        # self.optimal tuning lr=1e-4, momentum=0.85 for uniform data
        # self.optimizer = optim.SGD(self.model.parameters(), lr=1e-6, momentum=0.85)

        for epoch in range(self.args.epochs):
            train_loss = self.train(epoch)
            test_loss = self.test_by_loss(epoch)
            mean_L2_error = self.test_by_FEM(epoch)
            print('\n\n')

            if mean_L2_error < 1e-4:
                self.debug()
                exit()

            # if True:
            #     torch.save(self.model, self.args.root_path + '/' + self.args.model_path + '/linear/model_' + str(0))

    def debug(self):
        source = torch.ones(self.poisson.num_dofs).unsqueeze(0)
        solution = self.model(source)
        scalar_field_paraview(self.args, solution.data.numpy().flatten(), self.poisson, "ok")


if __name__ == "__main__":
    args = arguments.args
    trainer = TrainerNonlinear(args)
    trainer.run()